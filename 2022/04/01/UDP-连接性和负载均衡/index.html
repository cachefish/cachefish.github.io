<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"cachefish.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="UDP在大家的印象中是作为TCP的补充而存在，是无连接、不可靠、无序、无流量控制的传输层协议。UDP的无连接性已经深入人心，协议上的无连接性指的是一个UDP的Endpoint1(IP,PORT)，可以向多个UDP的Endpointi(IP,PORT)发送数据包，也可以接收来自多个UDP的Endpointi(IP,PORT)的数据包。实现上，考虑这样一个特殊情况：UDP Client 在Endpoi">
<meta property="og:type" content="article">
<meta property="og:title" content="ioreopen">
<meta property="og:url" content="https://cachefish.github.io/2022/04/01/UDP-%E8%BF%9E%E6%8E%A5%E6%80%A7%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/index.html">
<meta property="og:site_name" content="cachecatのBlog">
<meta property="og:description" content="UDP在大家的印象中是作为TCP的补充而存在，是无连接、不可靠、无序、无流量控制的传输层协议。UDP的无连接性已经深入人心，协议上的无连接性指的是一个UDP的Endpoint1(IP,PORT)，可以向多个UDP的Endpointi(IP,PORT)发送数据包，也可以接收来自多个UDP的Endpointi(IP,PORT)的数据包。实现上，考虑这样一个特殊情况：UDP Client 在Endpoi">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-04-01T11:30:00.000Z">
<meta property="article:modified_time" content="2022-04-27T07:58:37.054Z">
<meta property="article:tag" content="linux shell">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://cachefish.github.io/2022/04/01/UDP-%E8%BF%9E%E6%8E%A5%E6%80%A7%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>ioreopen | cachecatのBlog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">cachecatのBlog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">localhost</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">49</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://cachefish.github.io/2022/04/01/UDP-%E8%BF%9E%E6%8E%A5%E6%80%A7%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/2229.jfif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="来世做春风，浪漫且自由">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cachecatのBlog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ioreopen
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-01 19:30:00" itemprop="dateCreated datePublished" datetime="2022-04-01T19:30:00+08:00">2022-04-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-27 15:58:37" itemprop="dateModified" datetime="2022-04-27T15:58:37+08:00">2022-04-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux-shell/" itemprop="url" rel="index"><span itemprop="name">linux shell</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>UDP在大家的印象中是作为TCP的补充而存在，是无连接、不可靠、无序、无流量控制的传输层协议。UDP的无连接性已经深入人心，协议上的无连接性指的是一个UDP的Endpoint1(IP,PORT)，可以向多个UDP的Endpointi(IP,PORT)发送数据包，也可以接收来自多个UDP的Endpointi(IP,PORT)的数据包。实现上，考虑这样一个特殊情况：UDP Client 在Endpoint_C1只往UDP Server的Endpoint_S1发送数据包，并且只接收来自Endpoint_S1的数据包，把UDP通信双方都固定下来，这样不就形成一条单向的虚”连接”了么？</p>
<h4 id="UDP的”连接性”"><a href="#UDP的”连接性”" class="headerlink" title="UDP的”连接性”"></a>UDP的”连接性”</h4><p>估计很多同学认为UDP的连接性只是将UDP通信双方都固定下来了，一对一只是多对多的一个特例而已，这样UDP连接不连接到无所谓了。果真如此吗？其实不然，UDP的连接性可以带来以下两个好处：</p>
<h4 id="高效率、低消耗"><a href="#高效率、低消耗" class="headerlink" title="高效率、低消耗"></a>高效率、低消耗</h4><p>我们知道Linux系统有用户空间(用户态)和内核空间(内核态)之分，对于x86处理器以及大多数其它处理器，用户空间和内核空间之前的切换是比较耗时(涉及到上下文的保存和恢复，一般3种情况下会发生用户态到内核态的切换：发生系统调用时、产生异常时、中断时)。那么对于一个高性能的服务应该减少频繁不必要的上下文切换，如果切换无法避免，那么尽量减少用户空间和内核空间的数据交换，减少数据拷贝。熟悉socket编程的同学对下面几个系统调用应该比较熟悉了，由于UDP是基于用户数据报的，只要数据包准备好就应该调用一次send或sendto进行发包，当然包的大小完全由应用层逻辑决定的。细看两个系统调用的参数便知道，sendto比send的参数多2个，这就意味着每次系统调用都要多拷贝一些数据到内核空间，同时，参数到内核空间后，内核还需要初始化一些临时的数据结构来存储这些参数值(主要是对端Endpoint_S的地址信息)，在数据包发出去后，内核还需要在合适的时候释放这些临时的数据结构。进行UDP通信的时候，如果首先调用connect绑定对端Endpoint_S的后，那么就可以直接调用send来给对端Endpoint_S发送UDP数据包了。用户在connect之后，内核会永久维护一个存储对端Endpoint_S的地址信息的数据结构，内核不再需要分配&#x2F;删除这些数据结构，只需要查找就可以了，从而减少了数据的拷贝。这样对于connect方而言，该UDP通信在内核已经维护这一个“连接”了，那么在通信的整个过程中，内核都能随时追踪到这个“连接”。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">connect</span><span class="params">(<span class="type">int</span> socket, <span class="type">const</span> <span class="keyword">struct</span> sockaddr *address,<span class="type">socklen_t</span> address_len)</span></span>;     </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">send</span><span class="params">(<span class="type">int</span> socket, <span class="type">const</span> <span class="type">void</span> *buffer, <span class="type">size_t</span> length, <span class="type">int</span> flags)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">sendto</span><span class="params">(<span class="type">int</span> socket, <span class="type">const</span> <span class="type">void</span> *message, <span class="type">size_t</span> length, <span class="type">int</span> flags, <span class="type">const</span> <span class="keyword">struct</span> sockaddr *dest_addr,<span class="type">socklen_t</span> dest_len)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">recv</span><span class="params">(<span class="type">int</span> socket, <span class="type">void</span> *buffer, <span class="type">size_t</span> length, <span class="type">int</span> flags)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">recvfrom</span><span class="params">(<span class="type">int</span> socket, <span class="type">void</span> *restrict buffer, <span class="type">size_t</span> length,<span class="type">int</span> flags, <span class="keyword">struct</span> sockaddr *restrict address, <span class="type">socklen_t</span> *restrict address_len)</span></span>;</span><br></pre></td></tr></table></figure>
<h4 id="错误提示"><a href="#错误提示" class="headerlink" title="错误提示"></a>错误提示</h4><p>写UDP Socket程序的时候，有时候在第一次调用sendto给一个unconnected UDP socket发送UDP数据包时，接下来调用recvfrom()或继续调sendto的时候会返回一个ECONNREFUSED错误。对于一个无连接的UDP是不会返回这个错误的，之所以会返回这个错误，是因为你明确调用了connect去连接远端的Endpoint_S了。那么这个错误是怎么产生的呢？没有调用connect的UDP Socket为什么无法返回这个错误呢？<br>当一个UDP socket去connect一个远端Endpoint_S时，并没有发送任何的数据包，其效果仅仅是在本地建立了一个五元组映射，对应到一个对端，该映射的作用正是为了和UDP带外的ICMP控制通道捆绑在一起，使得UDP socket的接口含义更加丰满。这样内核协议栈就维护了一个从源到目的地的单向连接，当下层有ICMP(对于非IP协议，可以是其它机制)错误信息返回时，内核协议栈就能够准确知道该错误是由哪个用户socket产生的，这样就能准确将错误转发给上层应用了。对于下层是IP协议的时候，ICMP错误信息返回时，ICMP的包内容就是出错的那个原始数据包，根据这个原始数据包可以找出一个五元组，根据该五元组就可以对应到一个本地的connect过的UDP socket，进而把错误消息传输给该socket，应用程序在调用socket接口函数的时候，就可以得到该错误消息了。<br>对于一个无“连接”的UDP，sendto系统调用后，内核在将数据包发送出去后，就释放了存储对端Endpoint_S的地址等信息的数据结构了，这样在下层的协议有错误返回的时候，内核已经无法追踪到源socket了。<br>这里有个注意点要说明一下，由于UDP和下层协议都是不可靠的协议，所以，不能总是指望能够收到远端回复的ICMP包，例如：中间的一个节点或本机禁掉了ICMP，socket api调用就无法捕获这些错误了。</p>
<h4 id="UDP的负载均衡"><a href="#UDP的负载均衡" class="headerlink" title="UDP的负载均衡"></a>UDP的负载均衡</h4><p>在多核(多CPU)的服务器中，为了充分利用机器CPU资源，TCP服务器大多采用accept&#x2F;fork模式，TCP服务的MPM机制(multi processing module)，不管是预先建立进程池，还是每到一个连接创建新线程&#x2F;进程，总体都是源于accept&#x2F;fork的变体。然而对于UDP却无法很好的采用PMP机制，由于UDP的无连接性、无序性，它没有通信对端的信息，不知道一个数据包的前置和后续，它没有很好的办法知道，还有没后续的数据包以及如果有的话，过多久才会来，会来多久，因此UDP无法为其预先分配资源。</p>
<h5 id="端口重用SO-REUSEADDR、SO-REUSEPORT"><a href="#端口重用SO-REUSEADDR、SO-REUSEPORT" class="headerlink" title="端口重用SO_REUSEADDR、SO_REUSEPORT"></a>端口重用SO_REUSEADDR、SO_REUSEPORT</h5><p>要进行多处理，就免不了要在相同的地址端口上处理数据，SO_REUSEADDR允许端口的重用，只要确保四元组的唯一性即可。对于TCP，在bind的时候所有可能产生四元组不唯一的bind都会被禁止(于是，ip相同的情况下，TCP套接字处于TIME_WAIT状态下的socket，才可以重复绑定使用)；对于connect，由于通信两端中的本端已经明确了，那么只允许connect从来没connect过的对端(在明确不会破坏四元组唯一性的connect才允许发送SYN包)；对于监听listen端，四元组的唯一性油connect端保证就OK了。</p>
<p>TCP通过连接来保证四元组的唯一性，一个connect请求过来，accept进程accept完这个请求后(当然不一定要单独accept进程)，就可以分配socket资源来标识这个连接，接着就可以分发给相应的worker进程去处理该连接后续的事情了。这样就可以在多核服务器中，同时有多个worker进程来同时处理多个并发请求，从而达到负载均衡，CPU资源能够被充分利用。</p>
<p>UDP的无连接状态(没有已有对端的信息)，使得UDP没有一个有效的办法来判断四元组是否冲突，于是对于新来的请求，UDP无法进行资源的预分配，于是多处理模式难以进行，最终只能“守株待兔“，UDP按照固定的算法查找目标UDP socket，这样每次查到的都是UDP socket列表固定位置的socket。UDP只是简单基于目的IP和目的端口来进行查找，这样在一个服务器上多个进程内创建多个绑定相同IP地址(SO_REUSEADDR)，相同端口的UDP socket，那么你会发现，只有最后一个创建的socket会接收到数据，其它的都是默默地等待，孤独地等待永远也收不到UDP数据。UDP这种只能单进程、单处理的方式将要破灭UDP高效的神话，你在一个多核的服务器上运行这样的UDP程序，会发现只有一个核在忙，其他CPU核心处于空闲的状态。创建多个绑定相同IP地址，相同端口的UDP程序，只会起到容灾备份的作用，不会起到负载均衡的作用。</p>
<p>要实现多处理，那么就要改变UDP Socket查找的考虑因素，对于调用了connect的UDP Client而言，由于其具有了“连接”性，通信双方都固定下来了，那么内核就可以根据4元组完全匹配的原则来匹配。于是对于不同的通信对端，可以查找到不同的UDP Socket从而实现多处理。而对于server端，在使用SO_REUSEPORT选项(linux 3.9以上内核)，这样在进行UDP socket查找的时候，源IP地址和源端口也参与进来了，内核查找算法可以保证：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[1]</span> 固定的四元组的UDP数据包总是查找到同一个UDP Socket</span><br><span class="line"><span class="string">[2]</span> 不同的四元组的UDP数据包可能会查找到不同的UDP Socket</span><br></pre></td></tr></table></figure>
<p>这样对于不同client发来的数据包就能查找到不同的UDP socket从而实现多处理。这样看来，似乎采用SO_REUSEADDR、SO_REUSEPORT这两个socket选项并利用内核的socket查找算法，我们在多核CPU服务器上多个进程内创建多个绑定相同端口，相同IP地址的UDP socket就能做到负载均衡充分利用多核CPU资源了。然而事情远没这么顺利、简单。</p>
<h5 id="UDP-Socket列表变化问题"><a href="#UDP-Socket列表变化问题" class="headerlink" title="UDP Socket列表变化问题"></a>UDP Socket列表变化问题</h5><p>通过上面我们知道，在采用SO_REUSEADDR、SO_REUSEPORT这两个socket选项后，内核会根据UDP数据包的4元组来查找本机上的所有相同目的IP地址，相同目的端口的socket中的一个socket的位置，然后以这个位置上的socket作为接收数据的socket。那么要确保来至同一个Client Endpoint的UDP数据包总是被同一个socket来处理，就需要保证整个socket链表的socket所处的位置不能改变，然而，如果socket链表中间的某个socket挂了的话，就会造成socket链表重新排序，这样会引发问题。于是基本的解决方案是在整个服务过程中不能关闭UDP socket(当然也可以全部UDP socket都close掉，从新创建一批新的)。要保证这一点，我们需要所有的UDP socket的创建和关闭都由一个master进行来管理，worker进程只是负责处理对于的网络IO任务，为此我们需要socket在创建的时候要带有CLOEXEC标志(SOCK_CLOEXEC)。</p>
<h5 id="UDP和Epoll结合-UDP的Accept模型"><a href="#UDP和Epoll结合-UDP的Accept模型" class="headerlink" title="UDP和Epoll结合 - UDP的Accept模型"></a>UDP和Epoll结合 - UDP的Accept模型</h5><p>到此，为了充分利用多核CPU资源，进行UDP的多处理，我们会预先创建多个进程，每个进程都创建一个或多个绑定相同端口，相同IP地址(SO_REUSEADDR、SO_REUSEPORT)的UDP socket，这样利用内核的UDP socket查找算法来达到UDP的多进程负载均衡。然而，这完全依赖于Linux内核处理UDP socket查找时的一个算法，我们不能保证其它的系统或者未来的Linux内核不会改变算法的行为；同时，算法的查找能否做到比较好的均匀分布到不同的UDP socket，(每个处理进程只处理自己初始化时候创建的那些UDP socket)负载是否均衡是个问题。于是，我们多么想给UPD建立一个accept模型，按需分配UDP socket来处理。<br>在高性能Server编程中，对于TCP Server而已有比较成熟的解决方案，TCP天然的连接性可以充分利用epoll等高性能event机制，采用多路复用、异步处理的方式，哪个worker进程空闲就去accept连接请求来处理，这样就可以达到比较高的并发，可以极限利用CPU资源。然而对于UDP server而言，由于整个Svr就一个UDP socket，接收并响应所有的client请求，于是也就不存在什么多路复用的问题了。UDP svr无法充分利用epoll的高性能event机制的主要原因是，UDP svr只有一个UDP socket来接收和响应所有client的请求。然而如果能够为每个client都创建一个socket并虚拟一个“连接”与之对应，这样不就可以充分利用内核UDP层的socket查找结果和epoll的通知机制了么。server端具体过程如下：</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">UDP svr创建UDP socket fd,设置socket为REUSEADDR和REUSEPORT、同时bind本地地址local_addr</span><br><span class="line">listen_fd = socket(PF_INET, SOCK_DGRAM, <span class="number">0</span>)</span><br><span class="line">setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &amp;opt,sizeof(opt))</span><br><span class="line">setsockopt(listen_fd, SOL_SOCKET, SO_REUSEPORT, &amp;opt, sizeof(opt))</span><br><span class="line">bind(listen_fd, (<span class="keyword">struct</span> sockaddr *) &amp;local_addr, sizeof(<span class="keyword">struct</span> sockaddr))</span><br><span class="line">创建epoll fd，并将listen_fd放到epoll中 并监听其可读事件</span><br><span class="line">epoll_fd = epoll<span class="constructor">_create(1000)</span>;</span><br><span class="line">ep_event.events = EPOLLIN<span class="pattern-match">|<span class="constructor">EPOLLET</span>;</span></span><br><span class="line"><span class="pattern-match">ep<span class="constructor">_event</span>.data.fd = listen<span class="constructor">_fd</span>;</span></span><br><span class="line"><span class="pattern-match">epoll<span class="constructor">_ctl(<span class="params">epoll_fd</span> , EPOLL_CTL_ADD, <span class="params">listen_fd</span>, &amp;<span class="params">ep_event</span>)</span></span></span><br><span class="line"><span class="pattern-match"><span class="keyword">in</span><span class="constructor">_fds</span> = epoll<span class="constructor">_wait(<span class="params">epoll_fd</span>, <span class="params">in_events</span>, 1000, -1)</span>;</span></span><br><span class="line"><span class="pattern-match">epoll<span class="constructor">_wait</span>返回时，如果epoll<span class="constructor">_wait</span>返回的事件fd是listen<span class="constructor">_fd</span>，调用recvfrom接收client第一个<span class="constructor">UDP</span>包并根据recvfrom返回的client地址, 创建一个新的socket(<span class="keyword">new</span><span class="constructor">_fd</span>)与之对应，设置<span class="keyword">new</span><span class="constructor">_fd</span>为<span class="constructor">REUSEADDR</span>和<span class="constructor">REUSEPORT</span>、同时bind本地地址local<span class="constructor">_addr</span>，然后connect上recvfrom返回的client地址</span></span><br><span class="line"><span class="pattern-match">recvfrom(listen<span class="constructor">_fd</span>, buf, sizeof(buf), 0, (<span class="keyword">struct</span> sockaddr )&amp;client<span class="constructor">_addr</span>, &amp;client<span class="constructor">_len</span>)</span></span><br><span class="line"><span class="pattern-match"><span class="keyword">new</span><span class="constructor">_fd</span> = socket(<span class="constructor">PF_INET</span>, <span class="constructor">SOCK_DGRAM</span>, 0)</span></span><br><span class="line"><span class="pattern-match">setsockopt(<span class="keyword">new</span><span class="constructor">_fd</span> , <span class="constructor">SOL_SOCKET</span>, <span class="constructor">SO_REUSEADDR</span>, &amp;reuse,sizeof(reuse))</span></span><br><span class="line"><span class="pattern-match">setsockopt(<span class="keyword">new</span><span class="constructor">_fd</span> , <span class="constructor">SOL_SOCKET</span>, <span class="constructor">SO_REUSEPORT</span>, &amp;reuse, sizeof(reuse))</span></span><br><span class="line"><span class="pattern-match">bind(<span class="keyword">new</span><span class="constructor">_fd</span> , (<span class="keyword">struct</span> sockaddr ) &amp;local<span class="constructor">_addr</span>, sizeof(<span class="keyword">struct</span> sockaddr));</span></span><br><span class="line"><span class="pattern-match">connect(<span class="keyword">new</span><span class="constructor">_fd</span> , (<span class="keyword">struct</span> sockaddr <span class="operator">*</span>) &amp;client<span class="constructor">_addr</span>, sizeof(<span class="keyword">struct</span> sockaddr)</span></span><br><span class="line"><span class="pattern-match">将新创建的<span class="keyword">new</span><span class="constructor">_fd</span>加入到epoll中并监听其可读等事件</span></span><br><span class="line"><span class="pattern-match">client<span class="constructor">_ev</span>.events = <span class="constructor">EPOLLIN</span>;</span></span><br><span class="line"><span class="pattern-match">client<span class="constructor">_ev</span>.data.fd = <span class="keyword">new</span><span class="constructor">_fd</span> ;</span></span><br><span class="line"><span class="pattern-match">epoll<span class="constructor">_ctl(<span class="params">epoll_fd</span>, EPOLL_CTL_ADD, <span class="params">new_fd</span> , &amp;<span class="params">client_ev</span>)</span></span></span><br><span class="line"><span class="pattern-match">当epoll<span class="constructor">_wait</span>返回时，如果epoll<span class="constructor">_wait</span>返回的事件fd是<span class="keyword">new</span><span class="constructor">_fd</span> 那么就可以调用recvfrom来接收特定client的<span class="constructor">UDP</span>包了</span></span><br><span class="line"><span class="pattern-match">recvfrom(<span class="keyword">new</span><span class="constructor">_fd</span> , recvbuf, sizeof(recvbuf), 0, (<span class="keyword">struct</span> sockaddr <span class="operator">*</span>)&amp;client<span class="constructor">_addr</span>, &amp;client<span class="constructor">_len</span>)</span></span><br><span class="line"><span class="pattern-match">通过上面的步骤，这样<span class="constructor">UDP</span> svr就能充分利用epoll的事件通知机制了。第一次收到一个新的client的<span class="constructor">UDP</span>数据包，就创建一个新的<span class="constructor">UDP</span> socket和这个client对应，这样接下来的数据交互和事件通知都能准确投递到这个新的<span class="constructor">UDP</span> socket fd了。</span></span><br></pre></td></tr></table></figure>
<p>这里的UPD和Epoll结合方案，有以下几个注意点</p>
<p>[1] client要使用固定的ip和端口和server端通信，也就是client需要bind本地local address。<br>如果client没有bind本地local address，那么在发送UDP数据包的时候，可能是不同的Port了，这样如果server端的new_fd connect的是client的Port_CA端口，那么当Client的Port_CB端口的UDP数据包来到server时，内核不会投递到new_fd，相反是投递到listen_fd。由于需要bind和listen fd一样的IP地址和端口，因此SO_REUSEADDR和SO_REUSEPORT是必须的。<br>[2] 要小心处理上面步骤3中connect返回前，Client已经有多个UDP包到达Server端的情况。<br>如果server没处理好这个情况，在connect返回前，有2个UDP包到达server端了，这样server会new出两个new_fd1和new_fd2分别connect到client，那么后续的client的UDP到达server的时候，内核会投递UDP包给new_fd1和new_fd2中的一个</p>
<p>上面的UDP和Epoll结合的accept模型有个不好处理的小尾巴(也就是上面的注意点[2])，这个小尾巴的存在其本质是UDP和4元组没有必然的对应关系，也就是UDP的无连接性。</p>
<p>2.3 UDP Fork 模型 - UDP accept模型之按需建立UDP处理进程</p>
<p>为了充分利用多核CPU(为简化讨论，不妨假设为8核)，理想情况下，同时有8个工作进程在同时工作处理请求。于是我们会初始化8个绑定相同端口，相同IP地址(SO_REUSEADDR、SO_REUSEPORT)的UDP socket，接下来就靠内核的查找算法来达到client请求的负载均衡了。由于内核查找算法是固定的，于是，无形中所有的client被划分为8类，类型1的所有client请求全部被路由到工作进程1的UDP socket由工作进程1来处理，同样类型2的client的请求也全部被工作进程2来处理。这样的缺陷是明显的，比较容易造成短时间的负载极端不均衡。</p>
<p>一般情况下，如果一个UDP包能够标识一个请求，那么简单的解决方案是每个UDP socket n的工作进程n，自行fork出多个子进程来处理类型n的client的请求。这样每个子进程都直接recvfrom就OK了，拿到UDP请求包就处理，拿不到就阻塞。</p>
<p>然而，如果一个请求需要多个UDP包来标识的情况下，事情就没那么简单了，我们需要将同一个client的所有UDP包都路由到同一个工作子进程。为了简化讨论，我们将注意力集中在都是类型n的多个client请求UDP数据包到来的时候，我们怎么处理的问题，不同类型client的数据包路由问题交给内核了。这样，我们需要一个master进程来监听UDP socket的可读事件，master进程监听到可读事件，就采用MSG_PEEK选项来recvfrom数据包，如果发现是新的Endpoit(ip、port)Client的UDP包，那么就fork一个新的进行来处理该Endpoit的请求。具体如下</p>
<p>[1] master进程监听udp_socket_fd的可读事件：pfd.fd &#x3D; udp_socket_fd;pfd.events &#x3D; POLLIN; poll(pfd, 1, -1);<br>当可读事件到来，pfd.revents &amp; POLLIN 为true。探测一下到来的UDP包是否是新的client的UDP包:recvfrom(pfd.fd, buf, MAXSIZE, MSG_PEEK, (struct sockaddr )pclientaddr, &amp;addrlen);查找一下worker_list是否为该client创建过worker进程了。<br>[2] 如果没有查找到，就fork()处理进程来处理该请求，并将该client信息记录到worker_list中。查找到，那么continue，回到步骤[1]<br>[3] 每个worker子进程，保存自己需要处理的client信息pclientaddr。worker进程同样也监听udp_socket_fd的可读事件。poll(pfd, 1, -1);当可读事件到来，pfd.revents &amp; POLLIN 为true。探测一下到来的UDP包是否是本进程需要处理的client的UDP包:recvfrom(pfd.fd, buf, MAXSIZE, MSG_PEEK, (struct sockaddr )pclientaddr_2, &amp;addrlen); 比较一下pclientaddr和pclientaddr_2是否一致。</p>
<p>该fork模型很别扭，过多的探测行为，一个数据包来了，会”惊群”唤醒所有worker子进程，大家都去PEEK一把，最后只有一个worker进程能够取出UDP包来处理。同时到来的数据包只能排队被取出。更为严重的是，由于recvfrom的排他唤醒，可能会造成死锁。考虑下面一个场景：<br>假设有worker1、worker2、worker3、和master共四个进程都阻塞在poll调用上，client1的一个新的UDP包过来，这个时候，四个进程会被同时唤醒，worker1比较神速，赶在其他进程前将UPD包取走了(worker1可以处理client1的UDP包)，于是其他三个进程的recvfrom扑空，它们worker2、worker3、和master按序全部阻塞在recvfrom上睡眠(worker2、worker3排在master前面先睡眠的)。这个时候，一个新client4的UDP包packet4到来，(由于recvfrom的排他唤醒)这个时候只有worker2会从recvfrom的睡眠中醒来，然而worker而却不能处理该请求UDP包。如果没有新UDP包到来，那么packet4一直留在内核中，死锁了。之所以recv是排他的，是为了避免“承诺给一个进程”的数据被其他进程取走了。<br>通过上面的讨论，不管采用什么手段，UDP的accept模型总是那么别扭，总有一些无法自然处理的小尾巴。UDP的多路负载均衡方案不通用，不自然，其本因在于UPD的无连接性、无序性(无法标识数据的前续后继)。我们不知道client还在不在，于是难于决策虚拟的”连接”何时终止，以及何时结束掉fork出来的worker子进程(我们不能无限fork吧)。于是，在没有好的决策因素的时候，超时似乎是一个比较好选择，毕竟当所有的裁决手段都失效的时候，一切都要靠时间来冲淡。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>cachefish
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://cachefish.github.io/2022/04/01/UDP-%E8%BF%9E%E6%8E%A5%E6%80%A7%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/" title="ioreopen">https://cachefish.github.io/2022/04/01/UDP-连接性和负载均衡/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/linux-shell/" rel="tag"># linux shell</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/14/systemctl/" rel="prev" title="linux">
      <i class="fa fa-chevron-left"></i> linux
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/04/01/%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88/" rel="next" title="函数指针">
      函数指针 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#UDP%E7%9A%84%E2%80%9D%E8%BF%9E%E6%8E%A5%E6%80%A7%E2%80%9D"><span class="nav-number">1.</span> <span class="nav-text">UDP的”连接性”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AB%98%E6%95%88%E7%8E%87%E3%80%81%E4%BD%8E%E6%B6%88%E8%80%97"><span class="nav-number">2.</span> <span class="nav-text">高效率、低消耗</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA"><span class="nav-number">3.</span> <span class="nav-text">错误提示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#UDP%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="nav-number">4.</span> <span class="nav-text">UDP的负载均衡</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AB%AF%E5%8F%A3%E9%87%8D%E7%94%A8SO-REUSEADDR%E3%80%81SO-REUSEPORT"><span class="nav-number">4.1.</span> <span class="nav-text">端口重用SO_REUSEADDR、SO_REUSEPORT</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#UDP-Socket%E5%88%97%E8%A1%A8%E5%8F%98%E5%8C%96%E9%97%AE%E9%A2%98"><span class="nav-number">4.2.</span> <span class="nav-text">UDP Socket列表变化问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#UDP%E5%92%8CEpoll%E7%BB%93%E5%90%88-UDP%E7%9A%84Accept%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.3.</span> <span class="nav-text">UDP和Epoll结合 - UDP的Accept模型</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt=""
      src="/images/2229.jfif">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">来世做春风，浪漫且自由</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">49</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/cachefish" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cachefish" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/cachefish@163g.com" title="E-Mail → cachefish@163g.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cachecat</span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
-->

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":240,"height":360},"mobile":{"show":false},"react":{"opacityDefault":1,"opacityOnHover":1},"log":false,"tagMode":false});</script></body>
</html>
